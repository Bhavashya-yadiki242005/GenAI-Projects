Math Application with LangChain Agents (OCR + LLM)

This project is a Math Solver Web Application built using LangChain Agents, OCR, and LLMs.
It allows users to upload an image containing a math problem (printed or handwritten), automatically extracts the text, and then solves the problem step by step, finally showing the answer.

Instead of manually typing questions from textbooks or worksheets, this app reads directly from images and performs reasoning using a Large Language Model.

ğŸš€ Key Features

ğŸ“¸ Upload math questions as images

ğŸ” OCR-based text extraction using Tesseract

ğŸ¤– Step-by-step math reasoning using LLMs

ğŸ§  LangChain-powered prompt handling

ğŸŒ Simple and interactive Gradio web UI

ğŸ—ï¸ Project Architecture
Math-LangChain-App/
â”‚
â”œâ”€â”€ app.py                 # Main application file
â”œâ”€â”€ README.md              # Project documentation
â”œâ”€â”€ requirements.txt       # Required dependencies
â””â”€â”€ sample_images/         # Sample input images (optional)

ğŸ› ï¸ Tech Stack Used
Component	Technology
OCR	pytesseract
Image Processing	Pillow (PIL)
LLM Reasoning	OpenAI GPT (via LangChain)
Agent Framework	LangChain
UI Framework	Gradio
Language	Python
ğŸ“¦ Step 1: Install Dependencies

Install all required Python libraries using the command below:

pip install langchain langchain-community langchain-openai openai duckduckgo-search ddgs pytesseract Pillow gradio


ğŸ“Œ Important:
Make sure Tesseract OCR is installed on your system:

Windows:
Download from â†’ https://github.com/UB-Mannheim/tesseract/wiki

Linux:

sudo apt install tesseract-ocr


Mac:

brew install tesseract

ğŸ”‘ Step 2: Environment Setup (API Key)

Set your OpenAI API key as an environment variable.

Option 1: Inside Python (for testing)
import os
os.environ["OPENAI_API_KEY"] = "your-api-key"

Option 2: System Environment Variable (Recommended)

Windows (PowerShell):

setx OPENAI_API_KEY "your-api-key"


Linux / Mac:

export OPENAI_API_KEY="your-api-key"


âœ… You may also replace OpenAI with Gemini or other supported LLMs.

ğŸ“š Step 3: Import Libraries (Explanation of Each)
import gradio as gr
from PIL import Image
import pytesseract
from langchain_openai import ChatOpenAI
from langchain.agents import initialize_agent, Tool
from langchain.prompts import PromptTemplate

Explanation:

gradio â†’ Builds the web interface

PIL.Image â†’ Loads and processes images

pytesseract â†’ Extracts text from images (OCR)

ChatOpenAI â†’ Connects to OpenAI LLM

LangChain Tools & Agents â†’ Manages AI logic

PromptTemplate â†’ Formats structured prompts

ğŸ” Step 4: Optical Character Recognition (OCR)
Cell Explanation
def extract_text(image):
    return pytesseract.image_to_string(image)

What this does:

Takes an image as input

Extracts readable text using OCR

Returns raw text from the image

ğŸ¤– Step 5: LLM Setup & Math Prompt
llm = ChatOpenAI(model="gpt-4", temperature=0)

Explanation:

Uses GPT-4 for accurate math reasoning

temperature=0 ensures deterministic output

Prompt Template
math_prompt = PromptTemplate(
    input_variables=["question"],
    template="Solve this math related reasoning step by step and give only the final answer: {question}"
)

Purpose:

Forces the model to reason step-by-step

Ensures a clean final answer

Math Solver Function
def solve_math(query):
    return llm.invoke(math_prompt.format(question=query)).content

What happens:

Sends extracted text to the LLM

Returns the final computed answer

ğŸ”„ Step 6: Processing Pipeline (Core Logic)
def process_image(image):
    text = extract_text(image)
    if not text.strip():
        return "No text detected in the image."
    answer = solve_math(text)
    return f"Extracted Question:\n{text}\n\n Final Answer: {answer}"

Flow Explanation:

Receives image from user

Extracts text using OCR

Checks if text exists

Sends question to LLM

Returns both question + answer

ğŸŒ Step 7: Gradio Web Interface
with gr.Blocks(css="footer {display:none !important;}") as demo:


Creates the UI container and hides Gradio footer.

UI Layout
gr.Markdown("# Math Solver with LangChain and OCR")


Displays project title.

img_input = gr.Image(type="pil", label=" Upload Your Question Image")
output_box = gr.Textbox(label="Result", lines=10)


Image upload input

Text output box

Event Handling
img_input.upload(process_image, img_input, output_box)


Triggers processing when image is uploaded

clear_btn.click(lambda: "", None, output_box)


Clears output on button click

â–¶ï¸ Step 8: Run the Application
demo.launch(share=True)

Output:

Launches a local web app

Generates a public Gradio link

Allows image upload via:

File upload

Webcam

Clipboard paste

ğŸ–¼ï¸ Sample Output

Upload a math question image

Extracted text is displayed

Final answer is shown clearly

ğŸ¯ Use Cases

Students solving textbook problems

Teachers checking answers

Exam preparation

Accessibility for handwritten notes

AI-based education tools

ğŸš€ Future Enhancements

âœ… Show step-by-step reasoning

ğŸ§® Advanced math tools (symbolic math)

ğŸ—£ï¸ Voice input support

ğŸ“± Mobile-friendly UI

ğŸ§  Agent-based tool routing

ğŸ“Œ Conclusion

This project demonstrates how LangChain Agents + OCR + LLMs can be combined to build a real-world AI application.
